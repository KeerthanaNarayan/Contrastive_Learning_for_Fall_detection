{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWnl1R-kTuqd",
        "outputId": "e7405500-65b7-43e8-fabd-07322199fe90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 3.2126053250628477\n",
            "Epoch [2/10], Loss: 3.2353333870859347\n",
            "Epoch [3/10], Loss: 3.2186471160825527\n",
            "Epoch [4/10], Loss: 3.2049791441694295\n",
            "Epoch [5/10], Loss: 3.191840330442107\n",
            "Epoch [6/10], Loss: 3.20446091197415\n",
            "Epoch [7/10], Loss: 3.19332726100783\n",
            "Epoch [8/10], Loss: 3.2021928981285703\n",
            "Epoch [9/10], Loss: 3.195268111090501\n",
            "Epoch [10/10], Loss: 3.1905640964652813\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load and preprocess the accelerometer data\n",
        "def load_and_preprocess_data():\n",
        "    zip_path = 'fall-dataset-all.zip' #zip_path = 'fall-dataset-all.zip'\n",
        "\n",
        "    # Extract the CSV files from the zip file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        csv_files = [file for file in zip_ref.namelist() if file.endswith('.csv')]\n",
        "        zip_ref.extractall(members=csv_files)\n",
        "\n",
        "    # Read and concatenate the extracted CSV files into a DataFrame\n",
        "    data = pd.concat([pd.read_csv(file, encoding='latin-1') for file in csv_files], ignore_index=True)\n",
        "    accelerometer_data = data[[\"Acc(X)\", \"Acc(Y)\", \"Acc(Z)\", \"Rot(X)\", \"Rot(Y)\", \"Rot(Z)\", \"Pitch\", \"Roll\", \"Yaw\", \"Timestamp\"]].values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    standardized_data = scaler.fit_transform(accelerometer_data)\n",
        "\n",
        "    return standardized_data\n",
        "\n",
        "# Define the augmentation function\n",
        "def augment_function(sample):\n",
        "    augmented_sample = apply_augmentation(sample)\n",
        "    return augmented_sample\n",
        "\n",
        "# Define augmentation functions\n",
        "def apply_augmentation(sample):\n",
        "    augmented_sample = sample.copy()\n",
        "\n",
        "    # Noise Injection\n",
        "    noise = np.random.normal(loc=0, scale=0.1, size=augmented_sample.shape)\n",
        "    augmented_sample += noise\n",
        "\n",
        "    # Time Shifting\n",
        "    shift_amount = np.random.randint(low=1, high=len(augmented_sample))\n",
        "    augmented_sample = np.roll(augmented_sample, shift_amount, axis=0)\n",
        "\n",
        "    # Magnitude Scaling\n",
        "    scaling_factor = np.random.uniform(low=0.8, high=1.2)\n",
        "    augmented_sample *= scaling_factor\n",
        "\n",
        "    return augmented_sample\n",
        "\n",
        "# Define dataset class for accelerometer data\n",
        "class AccelerometerDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        augmented_sample_1 = augment_function(sample)\n",
        "        augmented_sample_2 = augment_function(sample)\n",
        "        return augmented_sample_1, augmented_sample_2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Load and preprocess your accelerometer data\n",
        "data = load_and_preprocess_data()\n",
        "\n",
        "# Create the dataset\n",
        "dataset = AccelerometerDataset(data)\n",
        "\n",
        "# Create the data loader\n",
        "batch_size = 64\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the SimCLR model architecture\n",
        "class SimCLRModel(nn.Module):\n",
        "    def __init__(self, num_steps):\n",
        "        super(SimCLRModel, self).__init__()\n",
        "        self.embedding_size = 128\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128 * (num_steps // 4), self.embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        embedding = self.fc(x)\n",
        "        return embedding\n",
        "\n",
        "# Define the contrastive loss function\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, embeddings_1, embeddings_2):\n",
        "        # Normalize the embeddings\n",
        "        embeddings_1 = nn.functional.normalize(embeddings_1, dim=1)\n",
        "        embeddings_2 = nn.functional.normalize(embeddings_2, dim=1)\n",
        "\n",
        "        # Calculate cosine similarity between the embeddings\n",
        "        similarities = torch.matmul(embeddings_1, embeddings_2.T) / self.temperature\n",
        "\n",
        "        # Generate target labels (1 for positive pairs, 0 for negative pairs)\n",
        "        labels = torch.arange(embeddings_1.size(0)).to(embeddings_1.device)\n",
        "\n",
        "        # Calculate contrastive loss\n",
        "        loss = nn.CrossEntropyLoss()(similarities, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "# Initialize the SimCLR model, contrastive loss, and optimizer\n",
        "num_steps = dataset[0][0].shape[0]\n",
        "model = SimCLRModel(num_steps).double()\n",
        "criterion = ContrastiveLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in data_loader:\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the batch of augmented samples\n",
        "        augmented_samples_1, augmented_samples_2 = batch\n",
        "\n",
        "        # Reshape the input data to include the num_channels dimension\n",
        "        augmented_samples_1 = augmented_samples_1.unsqueeze(1)\n",
        "        augmented_samples_2 = augmented_samples_2.unsqueeze(1)\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings_1 = model(augmented_samples_1.to(device).double())\n",
        "        embeddings_2 = model(augmented_samples_2.to(device).double())\n",
        "\n",
        "        # Calculate the contrastive loss\n",
        "        loss = criterion(embeddings_1, embeddings_2)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained SimCLR model\n",
        "torch.save(model.state_dict(), 'simclr_model.pth')\n",
        "\n",
        "# Define the fall detection model\n",
        "class FallDetectionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(FallDetectionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the fall detection model\n",
        "num_classes = 2  # Specify the number of classes for fall detection\n",
        "fall_model = FallDetectionModel(input_size=128, num_classes=num_classes)\n",
        "\n",
        "# Define the fall detection loss function\n",
        "fall_loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the fall detection optimizer\n",
        "fall_optimizer = optim.SGD(fall_model.parameters(), lr=0.001)\n",
        "\n",
        "# Load the saved SimCLR model and extract learned embeddings\n",
        "simclr_model = SimCLRModel(num_steps)\n",
        "simclr_model.load_state_dict(torch.load('simclr_model.pth'))\n",
        "simclr_model.eval()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjRiDmJ30aj",
        "outputId": "eef47f3f-d358-4b4e-a561-10e4a6e9db6c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimCLRModel(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To be incorporated into the previous load function\n",
        "# Load and preprocess the accelerometer data\n",
        "def load_and_preprocess(zip_path):\n",
        "\n",
        "    # Extract the CSV files from the zip file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        csv_files = [file for file in zip_ref.namelist() if file.endswith('.csv')]\n",
        "        zip_ref.extractall(members=csv_files)\n",
        "\n",
        "    # Read and concatenate the extracted CSV files into a DataFrame\n",
        "    data = pd.concat([pd.read_csv(file, encoding='latin-1') for file in csv_files], ignore_index=True)\n",
        "    accelerometer_data = data[[\"Acc(X)\", \"Acc(Y)\", \"Acc(Z)\", \"Rot(X)\", \"Rot(Y)\", \"Rot(Z)\", \"Pitch\", \"Roll\", \"Yaw\", \"Timestamp\"]].values\n",
        "    labels = data[\"Fall\"].values\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    standardized_data = scaler.fit_transform(accelerometer_data)\n",
        "\n",
        "    return standardized_data,labels"
      ],
      "metadata": {
        "id": "P0Sh2pgifAGT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Load the fall-dataset-features csv files\n",
        "# feature_files = glob.glob('fall-dataset-features/*.csv')\n",
        "# features = []\n",
        "# for feature_file in feature_files:\n",
        "#     df = pd.read_csv(feature_file)\n",
        "#     features.append(df.to_numpy())\n",
        "\n",
        "# # Split the features into train and test sets\n",
        "# train_features, test_features = np.split(features, [int(0.8 * len(features))])\n",
        "\n",
        "# Load the fall-dataset-raw csv files\n",
        "raw_files = \"fall-dataset-raw.zip\"#glob.glob('fall-dataset-raw/*.csv')\n",
        "raw_data, labels = load_and_preprocess(raw_files)\n",
        "\n",
        "# Split the raw data into train and test sets\n",
        "train_raw_data, test_raw_data = np.split(raw_data, [int(0.8 * len(raw_data))])\n",
        "\n",
        "# Split the raw data labels into train and test sets\n",
        "train_labels, test_labels = np.split(labels, [int(0.8 * len(labels))])\n",
        "\n",
        "# Define the train and test datasets\n",
        "train_dataset = AccelerometerDataset(train_raw_data)\n",
        "test_dataset = AccelerometerDataset(test_raw_data)\n"
      ],
      "metadata": {
        "id": "34aSnUkgeLyu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create the data loaders\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "WKsgovhlMox-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simclr_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kIydI1Pn3ev",
        "outputId": "84fc7aff-98df-4409-bf0a-065ed800b5cc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimCLRModel(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings = []\n",
        "for batch in train_data_loader:\n",
        "    augmented_samples_1, augmented_samples_2 = batch\n",
        "    augmented_samples_1 = augmented_samples_1.unsqueeze(1).to(device)\n",
        "    augmented_samples_2 = augmented_samples_2.unsqueeze(1).to(device)\n",
        "\n",
        "    embeddings_1 = simclr_model(augmented_samples_1.to(device).float())\n",
        "    embeddings_2 = simclr_model(augmented_samples_2.to(device).float())\n",
        "    train_embeddings.append(embeddings_1)\n",
        "    train_embeddings.append(embeddings_2)\n",
        "train_embeddings = torch.cat(train_embeddings, dim=0)\n",
        "\n",
        "test_embeddings = []\n",
        "for batch in test_data_loader:\n",
        "    augmented_samples_1, augmented_samples_2 = batch\n",
        "    augmented_samples_1 = augmented_samples_1.unsqueeze(1).to(device)\n",
        "    augmented_samples_2 = augmented_samples_2.unsqueeze(1).to(device)\n",
        "    embeddings_1 = simclr_model(augmented_samples_1.to(device).float())\n",
        "    embeddings_2 = simclr_model(augmented_samples_2.to(device).float())\n",
        "    test_embeddings.append(embeddings_1)\n",
        "    test_embeddings.append(embeddings_2)\n",
        "test_embeddings = torch.cat(test_embeddings, dim=0)\n"
      ],
      "metadata": {
        "id": "qmxzq2oflu8f"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)"
      ],
      "metadata": {
        "id": "yqLJ4OtBoY86"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the fall detection model to the same device as the embeddings\n",
        "fall_model = fall_model.to(device)\n",
        "\n",
        "# Training loop for the fall detection model\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    fall_model.train()\n",
        "    total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "    for i in range(len(train_embeddings)):\n",
        "        # Get the embeddings and labels for the current batch\n",
        "        embeddings = train_embeddings[i].unsqueeze(0)\n",
        "        labels = train_labels[i].unsqueeze(0)\n",
        "\n",
        "        # Move embeddings and labels to the same device as the model\n",
        "        embeddings = embeddings.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Convert the inputs and labels to torch.float32\n",
        "        embeddings = embeddings.float()\n",
        "        labels = labels.float()\n",
        "\n",
        "        # Forward pass through the fall detection model\n",
        "        outputs = fall_model(embeddings)\n",
        "\n",
        "        # Calculate the fall detection loss\n",
        "        fall_loss = fall_loss_function(outputs, labels.to(torch.int64))\n",
        "        total_loss += fall_loss.item()\n",
        "\n",
        "        # Zero the gradients\n",
        "        fall_optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        fall_loss.backward(retain_graph=True)\n",
        "        fall_optimizer.step()\n",
        "\n",
        "    # Evaluate the fall detection model\n",
        "    fall_model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Perform evaluation on the testing set\n",
        "        ...\n",
        "\n",
        "    # Calculate the average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_embeddings)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Fall Detection Loss: {avg_loss}\")\n"
      ],
      "metadata": {
        "id": "R90itV_M4XW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Move the fall detection model to the same device as the embeddings\n",
        "# fall_model = fall_model.to(device)\n",
        "\n",
        "# # Training loop for the fall detection model\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     fall_model.train()\n",
        "#     total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "#     for i in range(len(train_embeddings)):\n",
        "#         # Get the embeddings and labels for the current batch\n",
        "#         embeddings = train_embeddings[i].unsqueeze(0)\n",
        "#         labels = train_labels[i].unsqueeze(0)\n",
        "\n",
        "#         # Move embeddings and labels to the same device as the model\n",
        "#         embeddings = embeddings.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         # Convert the inputs and labels to torch.float32\n",
        "#         embeddings = embeddings.float()\n",
        "#         labels = labels.float()\n",
        "\n",
        "#         # Forward pass through the fall detection model\n",
        "#         outputs = fall_model(embeddings)\n",
        "\n",
        "#         # Calculate the fall detection loss\n",
        "#         fall_loss = fall_loss_function(outputs, labels.to(torch.int64))\n",
        "#         total_loss += fall_loss.item()\n",
        "\n",
        "#         # Zero the gradients\n",
        "#         fall_optimizer.zero_grad()\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         fall_loss.backward(retain_graph=True)\n",
        "#         fall_optimizer.step()\n",
        "\n",
        "#     # Evaluate the fall detection model\n",
        "#     fall_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         # Perform evaluation on the testing set\n",
        "#         ...\n",
        "\n",
        "#     # Calculate the average loss for the epoch\n",
        "#     avg_loss = total_loss / len(train_embeddings)\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Fall Detection Loss: {avg_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "bLJUMrEEz3oz",
        "outputId": "acc082b6-9b2e-4fb4-8b60-5f574913f0b9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-17bd5b6fd4da>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfall_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mfall_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create optimizer for the fall detection model\n",
        "# fall_optimizer = optim.Adam(fall_model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# # Move the fall optimizer  to the same device as the embeddings\n",
        "# fall_optimizer = fall_optimizer.to(device)\n",
        "\n",
        "# # Training loop for the fall detection model\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     fall_model.train()\n",
        "#     total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "#     for i in range(len(train_embeddings)):\n",
        "#         # Get the embeddings and labels for the current batch\n",
        "#         embeddings = train_embeddings[i].unsqueeze(0)\n",
        "#         labels = train_labels[i].unsqueeze(0)\n",
        "\n",
        "#         # Move embeddings and labels to the same device as the model\n",
        "#         embeddings = embeddings.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         # Move the fall detection model to the same device as the embeddings\n",
        "#         fall_model = fall_model.to(device)\n",
        "\n",
        "#         # Convert the inputs and labels to torch.float32\n",
        "#         embeddings = embeddings.float()\n",
        "#         labels = labels.float()\n",
        "\n",
        "#         # Forward pass through the fall detection model\n",
        "#         outputs = fall_model(embeddings)\n",
        "\n",
        "#         # Calculate the fall detection loss\n",
        "#         fall_loss = fall_loss_function(outputs, labels.to(torch.int64))\n",
        "#         total_loss += fall_loss.item()\n",
        "\n",
        "#         # Zero the gradients\n",
        "#         fall_optimizer.zero_grad()\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         fall_loss.backward(retain_graph=True) #fall_loss.backward()\n",
        "#         fall_optimizer.step()\n",
        "\n",
        "#     # Evaluate the fall detection model\n",
        "#     fall_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         # Perform evaluation on the testing set\n",
        "#         ...\n",
        "\n",
        "#     # Calculate the average loss for the epoch\n",
        "#     avg_loss = total_loss / len(train_embeddings)\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Fall Detection Loss: {avg_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "dcKNddN6qcYs",
        "outputId": "cc032a24-e0c0-4d79-e1b0-a84cb3ed414f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-786303f2c423>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Move the fall optimizer  to the same device as the embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfall_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfall_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Training loop for the fall detection model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training loop for the fall detection model\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     fall_model.train()\n",
        "#     for i in range(len(train_embeddings)):\n",
        "#         # Clear the gradients\n",
        "#         fall_optimizer.zero_grad()\n",
        "\n",
        "#         # Get the embeddings and labels for the current batch\n",
        "#         embeddings = train_embeddings[i].unsqueeze(0)\n",
        "#         labels = train_labels[i].unsqueeze(0)\n",
        "\n",
        "#         # Move embeddings and labels to the same device as the model\n",
        "#         embeddings = embeddings.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         # Move the fall detection model to the same device as the embeddings\n",
        "#         fall_model = fall_model.to(device)\n",
        "\n",
        "#         # Forward pass through the fall detection model\n",
        "#         outputs = fall_model(embeddings)\n",
        "\n",
        "#         # Calculate the fall detection loss\n",
        "#         fall_loss = fall_loss_function(outputs, labels)\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         fall_loss.backward()\n",
        "#         fall_optimizer.step()\n",
        "\n",
        "#     # Evaluate the fall detection model\n",
        "#     fall_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         # Perform evaluation on the testing set\n",
        "#         ...\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Fall Detection Loss: {fall_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "otXgFCibqGof",
        "outputId": "479001a7-cafb-4771-f63b-b9bb3bb064f3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-d5aeae39dd75>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Calculate the fall detection loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfall_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Double'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training loop for the fall detection model\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     fall_model.train()\n",
        "#     for i in range(len(train_embeddings)):\n",
        "#         # Clear the gradients\n",
        "#         fall_optimizer.zero_grad()\n",
        "\n",
        "#         # Get the embeddings and labels for the current batch\n",
        "#         embeddings = train_embeddings[i].unsqueeze(0)\n",
        "#         labels = train_labels[i].unsqueeze(0)\n",
        "\n",
        "#         # Move embeddings and labels to the same device as the model\n",
        "#         embeddings = embeddings.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         # Move the fall detection model to the same device as the embeddings\n",
        "#         fall_model = fall_model.to(device)\n",
        "\n",
        "#         # Forward pass through the fall detection model\n",
        "#         outputs = fall_model(embeddings)\n",
        "\n",
        "#         # Calculate the fall detection loss\n",
        "#         fall_loss = fall_loss_function(outputs, labels)\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         fall_loss.backward()\n",
        "#         fall_optimizer.step()\n",
        "\n",
        "#     # Evaluate the fall detection model\n",
        "#     fall_model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         # Perform evaluation on the testing set\n",
        "#         ...\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Fall Detection Loss: {fall_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "TRV8NAsHoHCD",
        "outputId": "008acfd6-a472-47a5-d1aa-4c78e4a980fe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d5aeae39dd75>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Calculate the fall detection loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfall_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Double'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_embeddings = []\n",
        "# with torch.no_grad():\n",
        "#     for i in range(len(train_dataset)):\n",
        "#         sample = train_dataset[i]\n",
        "#         augmented_sample_1, augmented_sample_2 = sample\n",
        "#         augmented_sample_1 = torch.from_numpy(augmented_sample_1).unsqueeze(0).to(device)\n",
        "#         augmented_sample_2 = torch.from_numpy(augmented_sample_2).unsqueeze(0).to(device)\n",
        "#         simclr_model.to(device)\n",
        "#         embeddings_1 = simclr_model(augmented_sample_1.float())\n",
        "#         embeddings_2 = simclr_model(augmented_sample_2.float())\n",
        "#         train_embeddings.append(embeddings_1)\n",
        "#         train_embeddings.append(embeddings_2)\n",
        "# train_embeddings = torch.cat(train_embeddings, dim=0)\n",
        "\n",
        "# test_embeddings = []\n",
        "# with torch.no_grad():\n",
        "#     for i in range(len(test_dataset)):\n",
        "#         sample = test_dataset[i]\n",
        "#         augmented_sample_1, augmented_sample_2 = sample\n",
        "#         augmented_sample_1 = torch.from_numpy(augmented_sample_1).unsqueeze(0).to(device)\n",
        "#         augmented_sample_2 = torch.from_numpy(augmented_sample_2).unsqueeze(0).to(device)\n",
        "#         embeddings_1 = simclr_model(augmented_sample_1.float())\n",
        "#         embeddings_2 = simclr_model(augmented_sample_2.float())\n",
        "#         test_embeddings.append(embeddings_1)\n",
        "#         test_embeddings.append(embeddings_2)\n",
        "# test_embeddings = torch.cat(test_embeddings, dim=0)\n"
      ],
      "metadata": {
        "id": "RsIZ-76hm5Ef"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train_embeddings = []\n",
        "\n",
        "# for batch in train_data_loader:\n",
        "#     augmented_samples_1, augmented_samples_2 = batch\n",
        "#     augmented_samples_1 = augmented_samples_1.unsqueeze(1)\n",
        "#     augmented_samples_2 = augmented_samples_2.unsqueeze(1)\n",
        "#     embeddings_1 = simclr_model(augmented_samples_1.to(device).float().to(device))\n",
        "#     embeddings_2 = simclr_model(augmented_samples_2.to(device).float())\n",
        "#     train_embeddings.append(embeddings_1)\n",
        "#     train_embeddings.append(embeddings_2)\n",
        "#     # train_labels.append(batch_labels)\n",
        "# train_embeddings = torch.cat(train_embeddings, dim=0)\n",
        "# # train_labels = torch.cat(train_labels, dim=0)\n",
        "\n",
        "# test_embeddings = []\n",
        "\n",
        "# for batch in test_data_loader:\n",
        "#     augmented_samples_1, augmented_samples_2 = batch\n",
        "#     augmented_samples_1 = augmented_samples_1.unsqueeze(1)\n",
        "#     augmented_samples_2 = augmented_samples_2.unsqueeze(1)\n",
        "#     embeddings_1 = simclr_model(augmented_samples_1.to(device).double())\n",
        "#     embeddings_2 = simclr_model(augmented_samples_2.to(device).double())\n",
        "#     test_embeddings.append(embeddings_1)\n",
        "#     test_embeddings.append(embeddings_2)\n",
        "#     # test_labels.append(batch_labels)\n",
        "# test_embeddings = torch.cat(test_embeddings, dim=0)\n",
        "# # test_labels = torch.cat(test_labels, dim=0)\n"
      ],
      "metadata": {
        "id": "3JFjh0Zy9s3j"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lO9-C37a30p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a88CZt4f9olp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rdg9PV789oqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########***********################"
      ],
      "metadata": {
        "id": "rrrddtUj9ota"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the trained SimCLR model\n",
        "# torch.save(model.state_dict(), 'simclr_model.pth')"
      ],
      "metadata": {
        "id": "Sisq7yccW2YH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# # Load the trained SimCLR model\n",
        "# model = torch.load('simclr_model.pth')\n",
        "\n",
        "# # Define the fall detection neural network\n",
        "# class FallDetectionNet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(FallDetectionNet, self).__init__()\n",
        "#         self.fc1 = nn.Linear(128, 64)\n",
        "#         self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Xc_2AQLnD048"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the fall detection neural network\n",
        "# net = FallDetectionNet()\n"
      ],
      "metadata": {
        "id": "6BwKjwjGREMK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Define the loss function and optimizer\n",
        "# criterion = nn.BCELoss()\n",
        "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "JwlHTC-ERHVs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDqRoKBmTMMS",
        "outputId": "f1589198-c5e4-40f5-989f-d1c60c4e9a07"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('backbone.0.weight',\n",
              "              tensor([[[-2.3754e-01,  7.4393e-01,  2.2094e-01]],\n",
              "              \n",
              "                      [[ 5.2533e-02, -8.4310e-02,  4.2818e-01]],\n",
              "              \n",
              "                      [[-1.5580e-01, -1.6563e-01, -2.3675e-02]],\n",
              "              \n",
              "                      [[ 4.1152e-01, -8.3230e-02, -3.3861e-02]],\n",
              "              \n",
              "                      [[-5.0727e-01, -3.3134e-01,  6.5924e-01]],\n",
              "              \n",
              "                      [[ 2.8789e-01,  1.5657e-01, -2.7034e-01]],\n",
              "              \n",
              "                      [[ 6.5816e-02,  2.5802e-02,  3.4281e-02]],\n",
              "              \n",
              "                      [[ 9.9532e-01,  2.7249e-01,  1.9407e-01]],\n",
              "              \n",
              "                      [[-3.1774e-01,  1.7254e-02, -8.5120e-01]],\n",
              "              \n",
              "                      [[-1.5200e-01,  4.6153e-01, -1.8625e-01]],\n",
              "              \n",
              "                      [[ 4.3908e-01,  2.4581e-01, -4.2816e-02]],\n",
              "              \n",
              "                      [[ 1.8044e-01,  2.7117e-01, -4.2979e-03]],\n",
              "              \n",
              "                      [[-1.0442e-01,  3.1701e-01,  3.3719e-01]],\n",
              "              \n",
              "                      [[ 2.6561e-01, -7.4957e-02, -4.4362e-01]],\n",
              "              \n",
              "                      [[-5.8326e-02,  7.5491e-01,  5.2530e-01]],\n",
              "              \n",
              "                      [[ 1.7269e-02,  5.9669e-01,  1.6465e-01]],\n",
              "              \n",
              "                      [[ 4.8725e-01, -1.8397e-01, -3.4217e-01]],\n",
              "              \n",
              "                      [[ 6.6276e-02,  1.7737e-03,  5.2385e-01]],\n",
              "              \n",
              "                      [[ 3.1766e-02, -9.7559e-01, -3.1559e-01]],\n",
              "              \n",
              "                      [[ 4.1616e-02,  3.6361e-01,  9.4925e-01]],\n",
              "              \n",
              "                      [[-2.5664e-01, -2.6412e-01, -2.7339e-01]],\n",
              "              \n",
              "                      [[-8.0754e-02, -2.4026e-01,  9.6898e-01]],\n",
              "              \n",
              "                      [[ 1.2534e-04,  5.8981e-05, -1.1910e-04]],\n",
              "              \n",
              "                      [[ 1.6486e-02, -4.7690e-01, -8.2115e-01]],\n",
              "              \n",
              "                      [[-2.5246e-01, -1.1265e-01,  2.2338e-01]],\n",
              "              \n",
              "                      [[ 6.8404e-02,  6.9579e-01, -5.9561e-02]],\n",
              "              \n",
              "                      [[ 1.3435e-01, -5.8533e-01,  6.2584e-02]],\n",
              "              \n",
              "                      [[ 8.7819e-03,  1.6638e-01,  3.2171e-01]],\n",
              "              \n",
              "                      [[ 2.0328e-01,  1.8211e-01,  2.2777e-01]],\n",
              "              \n",
              "                      [[-3.8573e-02,  3.4379e-01, -6.2911e-01]],\n",
              "              \n",
              "                      [[ 1.7042e-01, -1.6609e-01,  2.1482e-01]],\n",
              "              \n",
              "                      [[ 3.0234e-05,  7.3105e-05,  2.9459e-05]],\n",
              "              \n",
              "                      [[ 4.3830e-01,  4.5255e-01,  5.4987e-01]],\n",
              "              \n",
              "                      [[ 1.7337e-01, -1.1196e+00,  1.7041e-01]],\n",
              "              \n",
              "                      [[-7.0328e-01,  2.7484e-01,  5.4047e-01]],\n",
              "              \n",
              "                      [[ 1.2077e-01, -5.1419e-01,  5.2869e-01]],\n",
              "              \n",
              "                      [[ 4.4178e-01, -5.0969e-01,  5.5153e-02]],\n",
              "              \n",
              "                      [[-5.4180e-01,  6.7886e-01, -2.2281e-01]],\n",
              "              \n",
              "                      [[ 8.5428e-02,  1.0822e-01, -9.2295e-01]],\n",
              "              \n",
              "                      [[-9.3925e-01, -2.1863e-01, -1.7330e-01]],\n",
              "              \n",
              "                      [[ 6.2813e-01, -1.9641e-01,  8.0164e-01]],\n",
              "              \n",
              "                      [[ 7.6769e-01, -2.6866e-01, -1.1545e-01]],\n",
              "              \n",
              "                      [[ 4.2804e-01,  6.0194e-01,  4.6395e-01]],\n",
              "              \n",
              "                      [[ 9.1619e-01,  1.7600e-02, -3.5021e-01]],\n",
              "              \n",
              "                      [[-2.0218e-01, -1.2191e-01, -1.4549e-01]],\n",
              "              \n",
              "                      [[ 3.9451e-02, -2.5632e-01, -1.8372e-01]],\n",
              "              \n",
              "                      [[-5.2791e-01,  8.1199e-01, -7.9709e-02]],\n",
              "              \n",
              "                      [[-1.5579e-01,  1.7762e-02,  6.7670e-01]],\n",
              "              \n",
              "                      [[-4.5538e-01, -3.6632e-01, -4.6738e-01]],\n",
              "              \n",
              "                      [[-1.7596e-04, -2.8201e-04,  1.3080e-04]],\n",
              "              \n",
              "                      [[ 2.2864e-02, -3.0062e-01,  1.2485e-01]],\n",
              "              \n",
              "                      [[ 6.6633e-01,  2.7208e-02,  5.9806e-02]],\n",
              "              \n",
              "                      [[-9.8212e-01,  6.8999e-03,  5.6258e-03]],\n",
              "              \n",
              "                      [[ 9.7017e-02, -1.1402e-01, -1.6346e-01]],\n",
              "              \n",
              "                      [[-3.9569e-01,  9.0053e-02, -7.4043e-02]],\n",
              "              \n",
              "                      [[ 1.4081e-02,  1.4039e-01, -6.5870e-02]],\n",
              "              \n",
              "                      [[-7.7358e-01, -1.8372e-01,  1.8134e-01]],\n",
              "              \n",
              "                      [[-2.3705e-01, -3.3317e-02,  1.0462e-01]],\n",
              "              \n",
              "                      [[-3.6783e-01, -8.2219e-01,  6.8184e-02]],\n",
              "              \n",
              "                      [[-6.7975e-02,  8.3865e-02,  4.3823e-02]],\n",
              "              \n",
              "                      [[-2.4241e-01, -1.0341e+00, -2.5800e-01]],\n",
              "              \n",
              "                      [[ 2.3752e-01,  8.8646e-01, -5.5079e-01]],\n",
              "              \n",
              "                      [[ 2.9162e-02, -3.5425e-02, -1.8733e-01]],\n",
              "              \n",
              "                      [[-9.0762e-01,  2.6408e-01, -1.0781e-02]]], device='cuda:0',\n",
              "                     dtype=torch.float64)),\n",
              "             ('backbone.0.bias',\n",
              "              tensor([-0.6439, -0.1425,  0.3175, -0.0207, -0.5418, -0.0420,  0.1333, -0.6314,\n",
              "                      -0.3051, -0.0765, -0.0952,  0.0917, -0.0561, -0.0782, -0.5975, -0.1022,\n",
              "                      -0.3121, -0.0564, -0.3268, -0.7739,  0.1414, -1.0840, -0.0130, -0.4178,\n",
              "                       0.0875, -0.1590, -0.0721,  0.0959,  0.4236, -0.0863, -0.0253, -0.0100,\n",
              "                      -0.2779, -1.0331, -0.8304, -0.3307, -0.1446, -0.4544, -0.1734, -0.5252,\n",
              "                      -0.6989, -0.3884, -0.7297, -0.8759,  0.1836,  0.1823, -1.1391, -0.1623,\n",
              "                      -0.3018, -0.0275,  0.0548, -0.1384, -0.0798,  0.1853,  0.0927, -0.0032,\n",
              "                      -0.7390,  0.1471, -0.2161,  0.0895, -1.3131, -0.7449,  0.0538, -0.5612],\n",
              "                     device='cuda:0', dtype=torch.float64)),\n",
              "             ('backbone.3.weight',\n",
              "              tensor([[[-0.9932, -0.0870,  1.2155],\n",
              "                       [ 0.2105, -0.0169, -1.3809],\n",
              "                       [-0.1272, -0.4233, -0.1712],\n",
              "                       ...,\n",
              "                       [ 0.8040, -0.2846, -0.5749],\n",
              "                       [-0.1164,  0.0254,  0.0218],\n",
              "                       [-0.6539,  0.6070, -0.1428]],\n",
              "              \n",
              "                      [[-0.2662, -0.1445,  0.1074],\n",
              "                       [-0.2578, -0.1053, -0.3662],\n",
              "                       [ 0.0896, -0.1097, -0.1352],\n",
              "                       ...,\n",
              "                       [ 0.5509,  0.2374, -0.1503],\n",
              "                       [ 0.1872,  0.4856, -0.0052],\n",
              "                       [-0.0503,  0.1895, -0.5173]],\n",
              "              \n",
              "                      [[-0.2631,  0.0117, -0.1206],\n",
              "                       [ 0.1771,  0.0287,  0.1878],\n",
              "                       [ 0.3942, -0.1224, -0.1325],\n",
              "                       ...,\n",
              "                       [-0.8875, -0.4672, -0.4669],\n",
              "                       [ 0.3025, -0.0428,  0.2326],\n",
              "                       [-0.4463, -0.3000, -0.0887]],\n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "                      [[-0.2514, -0.1775, -0.1333],\n",
              "                       [ 0.0193,  0.0052, -0.2692],\n",
              "                       [ 0.0328, -0.1639, -0.0537],\n",
              "                       ...,\n",
              "                       [-0.0260,  0.0596, -0.6288],\n",
              "                       [ 0.0934, -0.0772,  0.0746],\n",
              "                       [-1.3367,  0.0963,  0.0105]],\n",
              "              \n",
              "                      [[ 0.1324,  0.1354, -0.0174],\n",
              "                       [-0.2358,  0.4668,  0.0909],\n",
              "                       [-0.7849, -0.0774, -0.2044],\n",
              "                       ...,\n",
              "                       [-1.0034,  0.0408, -0.0221],\n",
              "                       [ 0.4583, -0.0073,  0.1036],\n",
              "                       [ 0.2025, -0.3470,  0.0403]],\n",
              "              \n",
              "                      [[ 0.8334,  0.3480, -0.4195],\n",
              "                       [-0.0025,  0.0248, -0.2637],\n",
              "                       [ 0.7355, -0.4502, -0.3122],\n",
              "                       ...,\n",
              "                       [ 0.1225,  0.2451,  0.1757],\n",
              "                       [ 0.5012, -0.1852,  0.2117],\n",
              "                       [-0.3095, -0.0314, -0.0116]]], device='cuda:0', dtype=torch.float64)),\n",
              "             ('backbone.3.bias',\n",
              "              tensor([-0.4795, -0.0692, -0.1849, -0.0607, -0.3245, -0.2905, -0.4124, -0.3759,\n",
              "                      -0.6564, -0.1280, -0.3224, -0.1061, -0.7584, -0.5723, -0.1110, -0.1687,\n",
              "                      -0.2173, -0.9389, -0.2842,  0.0195, -0.0225, -0.3689, -0.9314,  0.0061,\n",
              "                      -0.0933, -0.1547, -0.7061, -0.3066,  0.0274, -0.5898, -0.2571,  0.1818,\n",
              "                      -0.5418,  0.0319, -0.7349, -0.4153, -0.0415, -0.0170,  0.0387, -0.6066,\n",
              "                      -0.3252, -0.1306, -0.2107, -0.1414, -0.0203, -0.0617,  0.0063,  0.0159,\n",
              "                      -0.2155, -0.0730, -0.1567, -0.2477, -0.8465,  0.0075, -0.2206, -0.2068,\n",
              "                      -0.1095, -0.1190, -0.3516,  0.0160, -0.1110, -0.1694, -0.2445, -0.0941,\n",
              "                      -1.1100,  0.0383, -0.0883, -0.1371,  0.0060, -0.1213, -0.1041, -0.6308,\n",
              "                      -0.0494, -0.4193,  0.0687,  0.0836, -0.0016, -0.2768, -0.1659, -0.2983,\n",
              "                      -0.0224, -0.7195, -0.2155, -0.0143, -0.0231,  0.0572, -0.6247, -0.2576,\n",
              "                      -0.4986, -0.5578, -0.1810, -0.2700, -0.5915, -0.6695, -0.3183,  0.0249,\n",
              "                       0.0104, -0.0260, -0.1010, -0.0292, -0.1077, -0.3853, -0.0110, -0.0735,\n",
              "                      -0.1051, -0.0997, -0.6394, -0.4748,  0.0099, -0.0307, -0.7061, -0.9722,\n",
              "                      -0.0124,  0.0765, -0.0025,  0.0407, -0.0728,  0.0983, -0.1167, -0.2337,\n",
              "                      -0.2335, -0.6884, -0.0984, -0.0532, -0.3617, -0.2120, -0.3205, -0.4044],\n",
              "                     device='cuda:0', dtype=torch.float64)),\n",
              "             ('fc.weight',\n",
              "              tensor([[-0.1659, -0.3903,  0.1583,  ..., -0.8783,  0.1076,  0.2016],\n",
              "                      [-0.1288, -0.4987,  0.4623,  ...,  0.3091,  0.7410,  0.9871],\n",
              "                      [-0.4678, -1.0213, -0.1855,  ...,  2.9308, -0.3599, -0.3695],\n",
              "                      ...,\n",
              "                      [-0.1783, -0.0657,  0.2213,  ..., -0.4951,  0.1703,  0.3277],\n",
              "                      [ 0.4754,  1.0891, -0.1862,  ..., -1.0566, -0.2540, -0.1951],\n",
              "                      [-0.1029,  0.0429,  0.1657,  ...,  3.0176,  0.0997,  0.2393]],\n",
              "                     device='cuda:0', dtype=torch.float64)),\n",
              "             ('fc.bias',\n",
              "              tensor([-0.0063,  0.0335,  0.1697,  0.1777, -0.0265, -0.1132,  0.3307,  0.3104,\n",
              "                       0.1534, -0.1371,  0.0319,  0.0054, -0.0979,  0.0224,  0.2126, -0.3495,\n",
              "                       0.1318, -0.0116,  0.1552,  0.2192,  0.1101,  0.1620,  0.1425,  0.0282,\n",
              "                      -0.2482,  0.0945, -0.0915, -0.0183, -0.1108,  0.1605, -0.0453,  0.2006,\n",
              "                      -0.0801,  0.0685,  0.0880, -0.0305, -0.1157, -0.3226,  0.0039,  0.2631,\n",
              "                      -0.1496,  0.1766,  0.0250, -0.0179,  0.2485, -0.1618, -0.2191,  0.0703,\n",
              "                       0.0462,  0.1329, -0.0735, -0.0346, -0.0113, -0.0157, -0.0474,  0.1533,\n",
              "                       0.1460,  0.1244, -0.3673, -0.1764, -0.0063,  0.2607,  0.0259, -0.1366,\n",
              "                       0.0329, -0.0409, -0.3480,  0.1469, -0.1718, -0.2511,  0.0067, -0.0361,\n",
              "                      -0.1369, -0.0451, -0.2347, -0.2438, -0.0898, -0.0402,  0.2323,  0.0549,\n",
              "                      -0.2633, -0.0515, -0.1180,  0.1381,  0.1554,  0.1219, -0.0273, -0.0008,\n",
              "                      -0.0024, -0.1781, -0.2745,  0.3233,  0.2787, -0.1312,  0.0550,  0.0911,\n",
              "                      -0.1397, -0.0932,  0.2743, -0.0066,  0.1792,  0.3259, -0.0254,  0.0683,\n",
              "                      -0.0218,  0.0314, -0.2224, -0.2633,  0.1398,  0.0653, -0.0334, -0.3349,\n",
              "                      -0.3025, -0.0446,  0.0489,  0.2188, -0.1039, -0.0555, -0.1009, -0.1091,\n",
              "                       0.0576,  0.1550, -0.0739, -0.0260, -0.0924, -0.0593,  0.0807, -0.0437],\n",
              "                     device='cuda:0', dtype=torch.float64))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Training loop\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch in data_loader:\n",
        "#         # Clear the gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Get the batch of augmented samples\n",
        "#         augmented_samples_1, augmented_samples_2 = batch\n",
        "\n",
        "#         # Reshape the input data to include the num_channels dimension\n",
        "#         augmented_samples_1 = augmented_samples_1.unsqueeze(1)\n",
        "#         augmented_samples_2 = augmented_samples_2.unsqueeze(1)\n",
        "\n",
        "#         # Forward pass\n",
        "#         embeddings_1 = model(augmented_samples_1.to(device).double())\n",
        "#         embeddings_2 = model(augmented_samples_2.to(device).double())\n",
        "\n",
        "#         # Calculate the fall probability\n",
        "#         fall_probability = net(embeddings_1 - embeddings_2)\n",
        "\n",
        "#         # Calculate the loss\n",
        "#         loss = criterion(fall_probability, labels)\n",
        "\n",
        "#         # Backward pass\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DXhYvUD5RJQ5",
        "outputId": "6bf5fe5f-bc71-4352-f2c4-937b9216202a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d70edfd3cf81>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0membeddings_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0membeddings_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert the model to a SimCLR class object\n",
        "# simclr_model = SimCLRModel()\n",
        "# simclr_model.double()\n",
        "\n",
        "# # Set the model parameters to the parameters of the trained model\n",
        "# simclr_model.load_state_dict(torch.load('simclr_model.pth'))\n",
        "# simclr_model.load_state_dict(torch.load('simclr_model.pth').double())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "xMy57iIGT1X4",
        "outputId": "f0d67b5b-0df4-408d-94ff-18340de926b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8662a715c501>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set the model parameters to the parameters of the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simclr_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msimclr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simclr_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'double'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Training loop\n",
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch in data_loader:\n",
        "#         # Clear the gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Get the batch of augmented samples\n",
        "#         augmented_samples_1, augmented_samples_2 = batch\n",
        "\n",
        "#         # Reshape the input data to include the num_channels dimension\n",
        "#         augmented_samples_1 = augmented_samples_1.unsqueeze(1)\n",
        "#         augmented_samples_2 = augmented_samples_2.unsqueeze(1)\n",
        "\n",
        "#         # Forward pass\n",
        "#         embeddings_1 = simclr_model(augmented_samples_1.to(device).double())\n",
        "#         embeddings_2 = simclr_model(augmented_samples_2.to(device).double())\n",
        "\n",
        "#         # Calculate the fall probability\n",
        "#         fall_probability = net(embeddings_1 - embeddings_2)\n",
        "\n",
        "#         # Calculate the loss\n",
        "#         loss = criterion(fall_probability, labels)\n",
        "\n",
        "#         # Backward pass\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "PJvl9PlyUWYe",
        "outputId": "e54b1412-14fa-4b61-9749-421f7b39b6e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-294fe5cf5d00>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0membeddings_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0membeddings_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-fa46d8fb5c1b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.DoubleTensor) and weight type (torch.DoubleTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUZIbEsnUb0t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}